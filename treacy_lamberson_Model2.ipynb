{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "df955ce39d0f31d56d4bb2fe0a613e5326ba60723fd33d8303a3aede8f65715c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Code Written By: Nathan Lamberson & Michael Treacy\n",
    "\n",
    "Method: Collaborative Filtering using Matrix Factorization\n",
    "\n",
    "Code Modeled off of: https://www.kaggle.com/jwyang91/steam-game-recommender/notebook\n",
    "\n",
    "This is accomplished by infering the preference of a new game based on the known preferences of a user, show as R = U * V.\n",
    "\n",
    "This model (Model 2) was used to develop ideas for the refined recommender (Model 1) that created a rating system based on the hours."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries to complete operations\n",
    "# Pandas for data processing\n",
    "# Numpy for linear algebra\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# List all files in the data directory\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries to complete operations\n",
    "# Pandas for data processing\n",
    "# Numpy for linear algebra\n",
    "# Tensorflow for ML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_curve, auc, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin Cleaning the Data\n",
    "# Set the filepath to the datasheet from Kaggle\n",
    "filePath = './data/steam-200k.csv'\n",
    "\n",
    "# Set the data to the information contained in the provided file\n",
    "fileData = pd.read_csv(filePath, header = None, names = ['UserID', 'Game', 'Action', 'Hours', '0'])\n",
    "\n",
    "# Show the first 5 rows of the data\n",
    "fileData.head()\n",
    "\n",
    "# Change the 'Hours' Header Column to 'HoursPlayed' and made the data a float32 value\n",
    "fileData['HoursPlayed'] = fileData['Hours'].astype('float32')\n",
    "\n",
    "# Change data in the file where the 'Action' row is purchased and 'Hours' is 1.0 to represent a value of 0 in the new 'HoursPlayed' column, since this \"Purchased\" with \"1.0\" hours means that the game was solely purchased and does not talk about the hours played. We want to ignore this for the cleansed data\n",
    "fileData.loc[(fileData['Action'] == 'purchase') & (fileData['Hours'] == 1.0), 'HoursPlayed'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       UserID                   Game  HoursPlayed\n",
       "65430    5250            Alien Swarm          4.9\n",
       "65424    5250        Cities Skylines        144.0\n",
       "65435    5250         Counter-Strike          0.0\n",
       "65436    5250  Counter-Strike Source          0.0\n",
       "65437    5250          Day of Defeat          0.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserID</th>\n      <th>Game</th>\n      <th>HoursPlayed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>65430</th>\n      <td>5250</td>\n      <td>Alien Swarm</td>\n      <td>4.9</td>\n    </tr>\n    <tr>\n      <th>65424</th>\n      <td>5250</td>\n      <td>Cities Skylines</td>\n      <td>144.0</td>\n    </tr>\n    <tr>\n      <th>65435</th>\n      <td>5250</td>\n      <td>Counter-Strike</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>65436</th>\n      <td>5250</td>\n      <td>Counter-Strike Source</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>65437</th>\n      <td>5250</td>\n      <td>Day of Defeat</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Set the UserID Column to data type int\n",
    "fileData.UserID = fileData.UserID.astype('int')\n",
    "\n",
    "# Sort the new fileData by 'UserID', 'Game', and the new 'HoursPlayed' column\n",
    "fileData = fileData.sort_values(['UserID', 'Game', 'HoursPlayed'])\n",
    "\n",
    "# Remove all duplicates game names tied to a UserID to remove \"add-ons\" to games, then drop the 'Action', 'Hours', and '0' columns\n",
    "cleanFileData = fileData.drop_duplicates(['UserID', 'Game'], keep = 'last').drop(['Action', 'Hours', '0'], axis = 1)\n",
    "\n",
    "# Show the first 5 rows of the new cleaned data\n",
    "cleanFileData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 12393 users and 5155 games in the data\n"
     ]
    }
   ],
   "source": [
    "# Get the total number of users by finding all unique UserID values\n",
    "numUsers = len(cleanFileData.UserID.unique())\n",
    "\n",
    "# Get the total number of games by finding all unique Game values\n",
    "numGames = len(cleanFileData.Game.unique())\n",
    "\n",
    "# Print this information to the screen\n",
    "print('There are {0} users and {1} games in the data'.format(numUsers, numGames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.20% of the user-item matrix is filled\n"
     ]
    }
   ],
   "source": [
    "# Calculate the sparsity of user-item matrix, based on the shape of the clean file data array shape\n",
    "sparsity = cleanFileData.shape[0] / (float(numUsers * numGames))\n",
    "\n",
    "# Print this information to the screen\n",
    "print('{:.2%} of the user-item matrix is filled'.format(sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a variable to a Counter container for the number of users\n",
    "userCounter = Counter()\n",
    "\n",
    "# Loop through the cleaned file data list to count the number of users\n",
    "for user in cleanFileData.UserID.tolist():\n",
    "    userCounter[user] = userCounter[user] + 1\n",
    "\n",
    "# Set a variable to a Counter container for the number of games\n",
    "gameCounter = Counter()\n",
    "\n",
    "# Loop through the cleaned file data list to count the number of games\n",
    "for game in cleanFileData.Game.tolist():\n",
    "    gameCounter[game] = gameCounter[game] + 1\n",
    "\n",
    "# Create\n",
    "user2index = {user: i for i, user in enumerate(cleanFileData.UserID.unique())}\n",
    "index2user = {i: user for user, i in user2index.items()}\n",
    "\n",
    "game2index = {game: i for i, game in enumerate(cleanFileData.Game.unique())}\n",
    "index2game = {i: game for game, i in game2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the user index to the lambda function of user2index[x] values (do not include header)\n",
    "userIndex = cleanFileData['UserID'].apply(lambda x: user2index[x]).values\n",
    "\n",
    "# Set the game index to the lambda function of game2index[x] values (do not include header)\n",
    "gameIndex = cleanFileData['GameIndex'] = cleanFileData['Game'].apply(lambda x: game2index[x]).values\n",
    "\n",
    "# Get the total hours played of all games (do not include header)\n",
    "hours = cleanFileData['HoursPlayed'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a baseline zero matrix modelled off of the number of users and number of games\n",
    "zeroMatrix = np.zeros(shape = (numUsers, numGames))\n",
    "\n",
    "# Set the user game preference matrix to the shape of the zero matrix\n",
    "userGamePreference = zeroMatrix.copy()\n",
    "\n",
    "# Fill the user game preference matrix with base values of 1 where applicable in regards to the previously calculated index values for users and games\n",
    "userGamePreference[userIndex, gameIndex] = 1\n",
    "\n",
    "# Set the user game interactions confidence matrix to the shape of the zero matrix\n",
    "userGameInteractions = zeroMatrix.copy()\n",
    "\n",
    "# Fill the user game interactions confidence matrix with value of hours played + 1 where applicable according to the userIndex and gameIndex values calculated earlier\n",
    "userGameInteractions[userIndex, gameIndex] = hours + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2189 users bought 10 or more games\n"
     ]
    }
   ],
   "source": [
    "# Set a base value for k\n",
    "k = 5\n",
    "\n",
    "# Count to total number of purchases for each UserID\n",
    "purchaseCounts = np.apply_along_axis(np.bincount, 1, userGamePreference.astype(int))\n",
    "\n",
    "# Find the total number of users who bought 2*k games (our baseline for prediction)\n",
    "buyersIndex = np.where(purchaseCounts[:, 1] >= (2 * k))[0]\n",
    "\n",
    "# Print the total number of users who bought 2*k games\n",
    "print('{0} users bought {1} or more games'.format(len(buyersIndex), (2 * k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep a total of 20% of the data to use for training\n",
    "testFrac = 0.2\n",
    "\n",
    "# Create a user index based on buyers\n",
    "testUsersIndex = np.random.choice(buyersIndex, size = int(np.ceil(len(buyersIndex) * testFrac)), replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a user index ending at position of the length of the test users index / 2\n",
    "valUsersIndex = testUsersIndex[:int(len(testUsersIndex) / 2)]\n",
    "\n",
    "# Create a user index beginning at position of the length of the test users index / 2 until the end\n",
    "testUsersIndex = testUsersIndex[int(len(testUsersIndex) / 2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing Function\n",
    "def dataProcess(data, train, test, userIndex, k):\n",
    "    # Loop over userIndex\n",
    "    for user in userIndex:\n",
    "        # Get all purchases\n",
    "        purchases = np.where(data[user, :] == 1)[0]\n",
    "\n",
    "        # Create a mask for purchases\n",
    "        mask = np.random.choice(purchases, size = k, replace = False)\n",
    "\n",
    "        # Train the data with the user and the mask\n",
    "        train[user, mask] = 0\n",
    "\n",
    "        # test the data with the user and mask data\n",
    "        test[user, mask] = data[user, mask]\n",
    "    \n",
    "    # Return train and test\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Train Matrix based off of the user game preference matrix\n",
    "trainMatrix = userGamePreference.copy()\n",
    "\n",
    "# Create a Test Matrix from the zero matrix\n",
    "testMatrix = zeroMatrix.copy()\n",
    "\n",
    "# Create a Validation Matrix from the zero matrix\n",
    "valMatrix = zeroMatrix.copy()\n",
    "\n",
    "# Mask the Train matrix and create the Validation and Test matricies\n",
    "trainMatrix, valMatrix = dataProcess(userGamePreference, trainMatrix, valMatrix, valUsersIndex, k)\n",
    "trainMatrix, testMatrix = dataProcess(userGamePreference, trainMatrix, testMatrix, testUsersIndex, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# Print the Test Matrix\n",
    "testMatrix[testUsersIndex[0], testMatrix[testUsersIndex[0], :].nonzero()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# Print the Train Matrix\n",
    "trainMatrix[testUsersIndex[0], testMatrix[testUsersIndex[0], :].nonzero()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Get a Preference Matrix\n",
    "preference = tf.placeholder(tf.float32, (numUsers, numGames))\n",
    "\n",
    "# Get the users interactions (hours played) on games in a Matrix\n",
    "interactions = tf.placeholder(tf.float32, (numUsers, numGames))\n",
    "\n",
    "# Get the users index\n",
    "usersIndex = tf.placeholder(tf.int32, (None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features\n",
    "numFeatures = 30\n",
    "\n",
    "# X Matrix for user preferences and features\n",
    "X = tf.Variable(tf.truncated_normal([numUsers, numFeatures], mean = 0, stddev = 0.05))\n",
    "\n",
    "# Y Matrix for user games and features\n",
    "Y = tf.Variable(tf.truncated_normal([numGames, numFeatures], mean = 0, stddev = 0.05))\n",
    "\n",
    "# Initialize the first confidence parameter\n",
    "confidenceParam = tf.Variable(tf.random_uniform([1], 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add user bias\n",
    "userBias = tf.Variable(tf.truncated_normal([numUsers, 1], stddev = 0.2))\n",
    "\n",
    "# Concatenate the vector to the user matrix\n",
    "XPlusBias = tf.concat([X, userBias, tf.ones((numUsers, 1), dtype = tf.float32)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add game bias\n",
    "itemBias = tf.Variable(tf.truncated_normal([numGames, 1], stddev = 0.2))\n",
    "\n",
    "# Concatenate the vector to the game matrix\n",
    "YPlusBias = tf.concat([Y, tf.ones((numGames, 1), dtype = tf.float32), itemBias], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Preference Matrix formed from Matrix Multiplication of the X and Y Matrix with bias applied\n",
    "predPreference = tf.matmul(XPlusBias, YPlusBias, transpose_b = True)\n",
    "\n",
    "# Construct the confidence matrix with the hours played and alpha parameter\n",
    "confidence = 1 + confidenceParam * interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost of the model, being the square sum of the actual preferences and the predicted preferences\n",
    "cost = tf.reduce_sum(tf.multiply(confidence, tf.square(tf.subtract(preference, predPreference))))\n",
    "\n",
    "# The l2 regulizer\n",
    "l2_square = tf.nn.l2_loss(X) + tf.nn.l2_loss(Y) + tf.nn.l2_loss(userBias) + tf.nn.l2_loss(itemBias)\n",
    "\n",
    "lambda_c = 0.01\n",
    "\n",
    "loss = cost + lambda_c * l2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "lr = 0.05\n",
    "\n",
    "# Optimize the training data based on loss\n",
    "optimize = tf.train.AdagradOptimizer(learning_rate = lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to help calculate the top k precision\n",
    "def topKPrecision(prediction, matrix, k, userIndex):\n",
    "    precisions = []\n",
    "\n",
    "    for user in userIndex:\n",
    "        # Find the best recommendation based off the predictions\n",
    "        recommendation = np.argsort(-prediction[user, :])\n",
    "\n",
    "        # Find the recommendations up to k\n",
    "        top_k = recommendation[:k]\n",
    "        \n",
    "        # Remove the labels\n",
    "        labels = matrix[user, :].nonzero()[0]\n",
    "\n",
    "        # Calculate the precision score\n",
    "        precision = len(set(top_k) & set(labels)) / float(k)\n",
    "        precisions.append(precision)\n",
    "    return np.mean(precisions)"
   ]
  },
  {
   "source": [
    "# Now is the training sessions\n",
    "# Iterate over the data 100 times\n",
    "iterations = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Loop over the data 100 times (based off iteration value above)\n",
    "    for i in range(iterations):\n",
    "        sess.run(optimize, feed_dict = {preference: trainMatrix, interactions: userGameInteractions})\n",
    "\n",
    "        # Print the current data for every 10 steps\n",
    "        if i % 10 == 0:\n",
    "            modLoss = sess.run(loss, feed_dict = {preference: trainMatrix, interactions: userGameInteractions})\n",
    "            modPred = predPreference.eval()\n",
    "            trainPrecision = topKPrecision(modPred, trainMatrix, k, valUsersIndex)\n",
    "            valPrecision = topKPrecision(modPred, valMatrix, k, valUsersIndex)\n",
    "            print('Iterations {0}...'.format(i), 'Training Loss {:.2f}...'.format(modLoss), 'Train Precision {:.3f}...'.format(trainPrecision), 'Val Precision {:.3f}'.format(valPrecision))\n",
    "    \n",
    "    # Calculate the precision and print it\n",
    "    rec = predPreference.eval()\n",
    "    testPrecision = topKPrecision(rec, testMatrix, k, testUsersIndex)\n",
    "    print('\\n')\n",
    "    print('Overall Test Precision: {:.3f}'.format(testPrecision))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iterations 0... Training Loss 3826740.25... Train Precision 0.078... Val Precision 0.016\n",
      "Iterations 10... Training Loss 318520.19... Train Precision 0.373... Val Precision 0.022\n",
      "Iterations 20... Training Loss 247674.06... Train Precision 0.457... Val Precision 0.037\n",
      "Iterations 30... Training Loss 218792.69... Train Precision 0.515... Val Precision 0.043\n",
      "Iterations 40... Training Loss 199725.83... Train Precision 0.553... Val Precision 0.047\n",
      "Iterations 50... Training Loss 185168.55... Train Precision 0.580... Val Precision 0.052\n",
      "Iterations 60... Training Loss 173109.50... Train Precision 0.603... Val Precision 0.050\n",
      "Iterations 70... Training Loss 162511.11... Train Precision 0.624... Val Precision 0.048\n",
      "Iterations 80... Training Loss 152735.88... Train Precision 0.637... Val Precision 0.048\n",
      "Iterations 90... Training Loss 143328.58... Train Precision 0.645... Val Precision 0.050\n",
      "\n",
      "\n",
      "Overall Test Precision: 0.058\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "numExamples = 10\n",
    "users = np.random.choice(testUsersIndex, size = numExamples, replace = False)\n",
    "\n",
    "# Sort the recommended games\n",
    "recGames = np.argsort(-rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "User #107818793 recommendations...\nRecommendations\nUnturned, Dota 2, Trove, Counter-Strike Global Offensive, Left 4 Dead 2\n\n\nActual Purchases\nARK Survival Evolved, Prison Architect, The Forest, Unturned, Grand Theft Auto V\n\n\nPrecision of 0.2\n-------------------------------\n\n\nUser #151600301 recommendations...\nRecommendations\nPlanetSide 2, Rocket League, Tom Clancy's Ghost Recon Phantoms - EU, ARK Survival Evolved, The Elder Scrolls V Skyrim\n\n\nActual Purchases\nDota 2, Don't Starve Together Beta, Unturned, Trove, Among Ripples\n\n\nPrecision of 0.0\n-------------------------------\n\n\nUser #190191843 recommendations...\nRecommendations\nTeam Fortress 2, DayZ, The Elder Scrolls V Skyrim, Dying Light, Heroes & Generals\n\n\nActual Purchases\nTeam Fortress 2, Let the Cat In, Mount Your Friends, AdVenture Capitalist, Metro 2033 Redux\n\n\nPrecision of 0.2\n-------------------------------\n\n\nUser #125141344 recommendations...\nRecommendations\nDota 2, Counter-Strike, Age of Empires II HD Edition, Total War SHOGUN 2, Empire Total War\n\n\nActual Purchases\nTeam Fortress 2, Unturned, Counter-Strike Nexon Zombies, No More Room in Hell, Tactical Intervention\n\n\nPrecision of 0.0\n-------------------------------\n\n\nUser #29983962 recommendations...\nRecommendations\nPath of Exile, Call of Duty Black Ops - Multiplayer, Garry's Mod, Call of Duty Black Ops, Warframe\n\n\nActual Purchases\nHalf-Life 2 Deathmatch, Half-Life 2 Lost Coast, Team Fortress 2, Left 4 Dead, Burnout Paradise The Ultimate Box\n\n\nPrecision of 0.0\n-------------------------------\n\n\nUser #85714521 recommendations...\nRecommendations\nCall of Duty Modern Warfare 2 - Multiplayer, DayZ, Call of Duty Modern Warfare 2, War Thunder, H1Z1\n\n\nActual Purchases\nDota 2, Team Fortress 2, Left 4 Dead 2, Unturned, God Mode\n\n\nPrecision of 0.0\n-------------------------------\n\n\nUser #44153929 recommendations...\nRecommendations\nDeathmatch Classic, Dota 2, Half-Life, Half-Life Blue Shift, Half-Life Opposing Force\n\n\nActual Purchases\nDeathmatch Classic, Dota 2, No More Room in Hell, APB Reloaded, Modular Combat\n\n\nPrecision of 0.4\n-------------------------------\n\n\nUser #217099682 recommendations...\nRecommendations\nDota 2, Counter-Strike Global Offensive, Team Fortress 2, Unturned, 7 Days to Die\n\n\nActual Purchases\nUnturned, Age of Conan Unchained - EU version, sZone-Online, APB Reloaded, PAYDAY The Web Series - Episode 1\n\n\nPrecision of 0.2\n-------------------------------\n\n\nUser #9134079 recommendations...\nRecommendations\nCounter-Strike Global Offensive, Call of Duty Black Ops - Multiplayer, Call of Duty Black Ops, Dota 2, Call of Duty Modern Warfare 3 - Multiplayer\n\n\nActual Purchases\nHalf-Life 2 Deathmatch, Half-Life 2 Episode Two, Half-Life 2 Lost Coast, Unreal Tournament Game of the Year Edition, DiRT 2\n\n\nPrecision of 0.0\n-------------------------------\n\n\nUser #202427012 recommendations...\nRecommendations\nUnturned, PAYDAY 2, Fallout 4, Team Fortress 2, Robocraft\n\n\nActual Purchases\nSkyrim High Resolution Texture Pack, Grand Theft Auto San Andreas, Archeblade, DRAGON BALL XENOVERSE, Need for Speed Hot Pursuit\n\n\nPrecision of 0.0\n-------------------------------\n\n\n"
     ]
    }
   ],
   "source": [
    "# Print the UserId as a header\n",
    "for user in users:\n",
    "    print('User #{0} recommendations...'.format(index2user[user]))\n",
    "    purchaseHistory = np.where(trainMatrix[user, :] != 0)[0]\n",
    "    recommendations = recGames[user, :]\n",
    "\n",
    "    newRecommendations = recommendations[~np.in1d(recommendations, purchaseHistory)][:k]\n",
    "\n",
    "    # Print their receommendations and actual purchases, and the precision score\n",
    "    print('Recommendations')\n",
    "    print(', '.join([index2game[game] for game in newRecommendations]))\n",
    "    print('\\n')\n",
    "    print('Actual Purchases')\n",
    "    print(', '.join([index2game[game] for game in np.where(testMatrix[user, :] != 0)[0]]))\n",
    "    print('\\n')\n",
    "    print('Precision of {0}'.format(len(set(newRecommendations) & set(np.where(testMatrix[user, :] != 0)[0])) / float(k)))\n",
    "    print('-------------------------------')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}